name: 'AI Code Review'
description: 'AI code review on pull requests using Claude — inline, incremental, deduplicated, Tilda-specific'
author: 'Tilda Bio'

inputs:
  anthropic-api-key:
    description: 'Anthropic API key for Claude'
    required: true
  gh-token:
    description: 'GitHub token for fetching PR diff and posting review comments'
    required: true
  pr-number:
    description: 'Pull request number'
    required: true
  repository:
    description: 'Repository name in format owner/repo'
    required: true
  model:
    description: 'Claude model to use'
    required: false
    default: 'claude-sonnet-4-5-20250929'
  max-diff-size:
    description: 'Maximum diff size in characters (to control token usage)'
    required: false
    default: '100000'
  max-comments:
    description: 'Maximum inline comments per review'
    required: false
    default: '5'
  context-file:
    description: 'Path to a repo-specific context file (e.g. .github/AI_CONTEXT.md). Requires checkout.'
    required: false
    default: ''
  custom-prompt:
    description: 'Additional instructions appended to the review prompt'
    required: false
    default: ''
  bot-username:
    description: 'GitHub username of the bot posting reviews (for deduplication)'
    required: false
    default: 'ojasgo'

outputs:
  review-status:
    description: 'Status of the review (success, skipped, error)'
    value: ${{ steps.run-review.outputs.review_status }}
  comments-posted:
    description: 'Number of inline comments posted'
    value: ${{ steps.run-review.outputs.comments_posted }}

runs:
  using: 'composite'
  steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Run AI review
      id: run-review
      shell: bash
      env:
        GH_TOKEN: ${{ inputs.gh-token }}
        ANTHROPIC_API_KEY: ${{ inputs.anthropic-api-key }}
        PR_NUMBER: ${{ inputs.pr-number }}
        REPOSITORY: ${{ inputs.repository }}
        MODEL: ${{ inputs.model }}
        MAX_DIFF_SIZE: ${{ inputs.max-diff-size }}
        MAX_COMMENTS: ${{ inputs.max-comments }}
        CONTEXT_FILE: ${{ inputs.context-file }}
        CUSTOM_PROMPT: ${{ inputs.custom-prompt }}
        BOT_USERNAME: ${{ inputs.bot-username }}
      run: |
        python3 << 'PYEOF'
        import json
        import os
        import subprocess
        import sys
        import urllib.request
        import urllib.error

        # ─── Config ───────────────────────────────────────────────────────
        PR_NUMBER      = os.environ["PR_NUMBER"]
        REPOSITORY     = os.environ["REPOSITORY"]
        MODEL          = os.environ["MODEL"]
        MAX_DIFF_SIZE  = int(os.environ["MAX_DIFF_SIZE"])
        MAX_COMMENTS   = int(os.environ["MAX_COMMENTS"])
        CONTEXT_FILE   = os.environ.get("CONTEXT_FILE", "")
        CUSTOM_PROMPT  = os.environ.get("CUSTOM_PROMPT", "")
        BOT_USERNAME   = os.environ.get("BOT_USERNAME", "ojasgo")
        ANTHROPIC_KEY  = os.environ["ANTHROPIC_API_KEY"]

        SEVERITY_RANK = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}

        def gh(*args):
            r = subprocess.run(["gh"] + list(args), capture_output=True, text=True, timeout=120)
            if r.returncode != 0:
                print(f"gh error: {' '.join(args)}\n{r.stderr}", file=sys.stderr)
            return r.stdout.strip()

        def out(key, val):
            with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                f.write(f"{key}={val}\n")

        # ─── 1. PR metadata ──────────────────────────────────────────────
        print(f"Fetching PR #{PR_NUMBER}...")
        pr = json.loads(gh("pr", "view", PR_NUMBER, "--repo", REPOSITORY,
                           "--json", "title,body,baseRefName,headRefName,commits"))
        pr_title    = pr["title"]
        pr_body     = (pr.get("body") or "")[:2000]
        base_branch = pr["baseRefName"]
        head_branch = pr["headRefName"]
        commits     = pr.get("commits", [])
        head_sha    = commits[-1]["oid"] if commits else ""
        print(f"  {head_branch} -> {base_branch} ({len(commits)} commits, HEAD {head_sha[:8]})")

        # ─── 2. Incremental: find last AI review commit ──────────────────
        print("Checking for previous AI reviews...")
        raw = gh("api", f"repos/{REPOSITORY}/pulls/{PR_NUMBER}/reviews", "--paginate")
        reviews = json.loads(raw) if raw else []

        last_sha = None
        for rev in reversed(reviews):
            if (rev.get("user", {}).get("login") == BOT_USERNAME
                    and "AI Code Review" in (rev.get("body") or "")):
                last_sha = rev.get("commit_id")
                break

        # ─── 3. Get diff ─────────────────────────────────────────────────
        incremental = False
        if last_sha:
            print(f"  Previous review at {last_sha[:8]}. Diffing incremental...")
            diff = gh("api", f"repos/{REPOSITORY}/compare/{last_sha}...{head_sha}",
                      "--jq", '.files[]? | "diff --git a/" + .filename + " b/" + .filename + "\\n" + (.patch // "")')
            if diff:
                incremental = True
            else:
                print("  No new changes since last review. Skipping.")
                out("review_status", "skipped"); out("comments_posted", "0"); sys.exit(0)
        else:
            print("  First review — full PR diff.")
            diff = gh("pr", "diff", PR_NUMBER, "--repo", REPOSITORY)

        if not diff:
            print("  Empty diff."); out("review_status", "skipped"); out("comments_posted", "0"); sys.exit(0)

        print(f"  Diff: {len(diff)} chars (incremental={incremental})")
        if len(diff) > MAX_DIFF_SIZE:
            diff = diff[:MAX_DIFF_SIZE] + "\n\n... [DIFF TRUNCATED] ..."

        # ─── 4. Existing comments for dedup ───────────────────────────────
        raw = gh("api", f"repos/{REPOSITORY}/pulls/{PR_NUMBER}/comments", "--paginate")
        existing = json.loads(raw) if raw else []
        seen = set()
        for c in existing:
            if c.get("user", {}).get("login") == BOT_USERNAME:
                seen.add(f"{c.get('path','')}:{c.get('line') or c.get('original_line') or 0}")
        print(f"  {len(seen)} existing bot comments for dedup")

        # ─── 5. Read repo context file ────────────────────────────────────
        repo_context = ""
        if CONTEXT_FILE and os.path.isfile(CONTEXT_FILE):
            with open(CONTEXT_FILE) as f:
                repo_context = f.read()
            print(f"  Loaded context from {CONTEXT_FILE} ({len(repo_context)} chars)")

        # ─── 6. Build prompt ──────────────────────────────────────────────
        # System prompt = REVIEW.md guidelines (Tilda-specific)
        system_prompt = """You are a code review agent for Tilda, a biotech platform.

RULES — read these first:
- Signal > volume. If unsure whether something is a real issue, do NOT comment.
- Report ALL CRITICAL issues — no limit. For HIGH/MEDIUM, limit to """ + str(MAX_COMMENTS) + """ comments. Prioritize highest impact.
- If a CRITICAL issue exists, report it first. Continue reviewing for other CRITICAL issues but skip non-critical observations.
- Return ONLY valid JSON. No markdown fences, no explanation outside JSON.
- Each comment: file path + line number (from ADDED side, calculated from @@ hunk headers) + 1-4 line body with concrete fix.
- Severity tags: [CRITICAL] must fix before merge, [HIGH] strongly recommended, [MEDIUM] improvement.
- Do NOT use [LOW]. If it is not materially impactful, do not comment.
- If no issues: return {"summary": "LGTM", "comments": []}
- No summary paragraph. No praise. Only findings.

REPOSITORY CONTEXT:
This is a monorepo with:
- ~18 Go microservices (execsvc, docsvc, patientsvc, schedsvc, enrollsvc, studiosvc, finsvc, notifsvc, dslsvc, authz, dashQL, dashRsvc, regsvc, advpsvc, workplansvc, datasvc, payoutsvc, tusker)
- Shared Go libraries (common/, tildadb/, tildaobj/, api/, tlang/, util/) — changes here affect many services
- Python AI services under data-science/ (studioai, virtual_assistant, docproc, exportsvc) — LangChain, OpenAI, Neo4j, PubSub
- Neo4j as primary database with Cypher queries
- Google Cloud Pub/Sub for async messaging (at-least-once delivery — consumers must be idempotent)
- GraphQL (gqlgen) in dashQL
- GitHub Actions CI/CD

PR NECESSITY CHECK (do first):
- Is this PR necessary? Could the goal be achieved simpler?
- Does the diff include unrelated changes? Unnecessary abstractions?
- Flag over-engineering before reviewing code details.

WHAT TO CHECK:

1. Correctness: Logic errors, null dereferences, wrong variable, off-by-one, incorrect control flow
2. Security: Hardcoded secrets, injection (SQL, Cypher, command, prompt), missing auth, PHI/PII exposure, insecure crypto
3. Concurrency: Goroutines without context cancellation, unsafe concurrent map access, race conditions, blocking calls in goroutines
4. Distributed reliability: Non-idempotent retries, at-least-once vs exactly-once confusion, missing partial failure handling, PubSub ack/nack errors silently swallowed
5. Error handling: Silent except/pass, missing error handling on DB/API/message paths, ignored Go error returns, panics in production
6. Data integrity: Messages dropped, partial writes without rollback, state corruption, Neo4j session/transaction not closed
7. Breaking changes: Shared library changes without downstream consideration, API contract changes, schema changes breaking rolling deploys, removed fields callers depend on
8. Performance: N+1 Cypher queries in loops, unbounded memory, missing pagination, full graph scans
9. Cross-service impact: Changes to common/, tildaobj/, tildadb/ affect all services — increase severity by one level for shared code changes

GO-SPECIFIC:
- Missing or ignored error returns
- Goroutines without context cancellation
- Unsafe concurrent map access
- Panics in production paths
- Neo4j session/transaction not closed
- Cypher injection via string concatenation (must use parameterized queries)
- Missing timeout on external calls

PYTHON-SPECIFIC:
- Blocking I/O inside async code
- Silent exception swallowing (bare except/pass on critical paths)
- User input concatenated into LLM prompts
- LLM responses used without validation
- Unbounded agent loops (missing max iterations)
- Missing resource cleanup

NEO4J/CYPHER:
- Non-existent node labels or relationship types (verify against tildaobj/ if visible)
- Relationships traversed in wrong direction
- String concatenation instead of parameterized queries
- Queries causing full graph scans (missing WHERE clause on indexed property)

WHAT NOT TO CHECK:
- Formatting, naming, import ordering, type hints
- Missing docstrings or comments
- "Consider using X instead of Y" suggestions
- Hypothetical issues requiring full codebase context to verify
- Non-critical optimizations
- Alternative architectures

Response format:
{
  "comments": [
    {"path": "file.go", "line": 42, "body": "[CRITICAL] Description. Fix: ..."}
  ]
}"""

        # Append repo-specific context if available
        if repo_context:
            system_prompt += "\n\nADDITIONAL REPO CONTEXT:\n" + repo_context

        if CUSTOM_PROMPT:
            system_prompt += "\n\nADDITIONAL INSTRUCTIONS:\n" + CUSTOM_PROMPT

        label = "incremental (new commits only)" if incremental else "full PR"
        user_prompt = f"""Review this {label} diff. Return JSON only.

Title: {pr_title}
Description: {pr_body}
Branch: {head_branch} -> {base_branch}

Diff:
```diff
{diff}
```"""

        # ─── 7. Call Claude ───────────────────────────────────────────────
        print(f"Calling Claude ({MODEL})...")
        payload = {
            "model": MODEL,
            "max_tokens": 4096,
            "system": system_prompt,
            "messages": [{"role": "user", "content": user_prompt}]
        }

        req = urllib.request.Request(
            "https://api.anthropic.com/v1/messages",
            data=json.dumps(payload).encode(),
            headers={
                "Content-Type": "application/json",
                "x-api-key": ANTHROPIC_KEY,
                "anthropic-version": "2023-06-01",
            },
            method="POST"
        )

        try:
            with urllib.request.urlopen(req, timeout=120) as resp:
                resp_data = json.loads(resp.read())
        except urllib.error.HTTPError as e:
            body = e.read().decode() if e.fp else ""
            print(f"::error::Claude API HTTP {e.code}: {body}")
            out("review_status", "error"); out("comments_posted", "0"); sys.exit(1)

        text = resp_data.get("content", [{}])[0].get("text", "")

        # Strip code fences
        if text.startswith("```"):
            lines = text.split("\n")
            if lines[0].startswith("```"): lines = lines[1:]
            if lines and lines[-1].strip() == "```": lines = lines[:-1]
            text = "\n".join(lines)

        try:
            review = json.loads(text)
        except json.JSONDecodeError:
            print(f"::error::Invalid JSON from Claude:\n{text[:500]}")
            out("review_status", "error"); out("comments_posted", "0"); sys.exit(1)

        comments = review.get("comments", [])
        print(f"  Claude returned {len(comments)} comment(s)")

        # ─── 8. Filter: dedup, severity, cap ──────────────────────────────
        filtered = []
        skip_sev = 0
        skip_dup = 0

        for c in comments:
            body = c.get("body", "")
            path = c.get("path", "")
            line = c.get("line", 0)

            sev = "MEDIUM"
            for s in SEVERITY_RANK:
                if f"[{s}]" in body:
                    sev = s; break

            # Drop LOW
            if SEVERITY_RANK.get(sev, 3) > 2:
                skip_sev += 1; continue

            # Dedup
            if f"{path}:{line}" in seen:
                skip_dup += 1; continue

            filtered.append({"path": path, "line": line, "body": body, "_sev": sev})

        filtered.sort(key=lambda x: SEVERITY_RANK.get(x["_sev"], 3))

        # All CRITICALs always go through, cap only applies to HIGH/MEDIUM
        criticals = [c for c in filtered if c["_sev"] == "CRITICAL"]
        non_criticals = [c for c in filtered if c["_sev"] != "CRITICAL"]
        capped_non_criticals = non_criticals[:MAX_COMMENTS]
        final = criticals + capped_non_criticals
        skipped_cap = max(0, len(non_criticals) - MAX_COMMENTS)

        print(f"  Posting {len(final)} ({len(criticals)} CRITICAL uncapped + {len(capped_non_criticals)} HIGH/MEDIUM, skipped: {skip_sev} low-severity, {skip_dup} duplicates, {skipped_cap} over cap)")

        # ─── 9. Post review ──────────────────────────────────────────────
        label = "incremental" if incremental else "full"
        sev_counts = {}
        for c in final:
            s = c["_sev"]; sev_counts[s] = sev_counts.get(s, 0) + 1
        sev_line = ", ".join(f"{v} {k}" for k, v in sorted(sev_counts.items(), key=lambda x: SEVERITY_RANK.get(x[0], 3)))

        body_text = f"## AI Code Review ({label})"
        if sev_line:
            body_text += f"\n\n{sev_line}"
        if skip_dup:
            body_text += f"\n\n_{skip_dup} duplicate(s) skipped_"
        body_text += "\n\n---\n*Powered by Claude*"

        if not final:
            f = "/tmp/ai_review_lgtm.md"
            with open(f, "w") as fh:
                fh.write(f"## AI Code Review ({label})\n\nLGTM — no critical issues found.\n\n---\n*Powered by Claude*")
            gh("pr", "comment", PR_NUMBER, "--repo", REPOSITORY, "--body-file", f)
            print("  Posted LGTM")
            out("review_status", "success"); out("comments_posted", "0"); sys.exit(0)

        # Try batch post
        payload = {
            "commit_id": head_sha,
            "body": body_text,
            "event": "COMMENT",
            "comments": [{"path": c["path"], "line": c["line"], "side": "RIGHT", "body": c["body"]} for c in final]
        }
        pf = "/tmp/ai_review_payload.json"
        with open(pf, "w") as f:
            json.dump(payload, f)

        r = subprocess.run(
            ["gh", "api", "--method", "POST", "-H", "Accept: application/vnd.github+json",
             f"repos/{REPOSITORY}/pulls/{PR_NUMBER}/reviews", "--input", pf],
            capture_output=True, text=True, timeout=60
        )

        if r.returncode == 0:
            print(f"  Posted {len(final)} inline comment(s)")
            out("review_status", "success"); out("comments_posted", str(len(final))); sys.exit(0)

        # Batch failed — post one by one, skip line mismatches
        print(f"  Batch failed, posting individually...")
        posted = 0
        for i, c in enumerate(final):
            sp = {"commit_id": head_sha, "body": body_text if i == 0 else "", "event": "COMMENT",
                  "comments": [{"path": c["path"], "line": c["line"], "side": "RIGHT", "body": c["body"]}]}
            sf = f"/tmp/ai_review_{i}.json"
            with open(sf, "w") as f:
                json.dump(sp, f)
            sr = subprocess.run(
                ["gh", "api", "--method", "POST", "-H", "Accept: application/vnd.github+json",
                 f"repos/{REPOSITORY}/pulls/{PR_NUMBER}/reviews", "--input", sf],
                capture_output=True, text=True, timeout=30
            )
            if sr.returncode == 0:
                posted += 1
            else:
                print(f"    Skipped {c['path']}:{c['line']} (line not in diff)")

        print(f"  Posted {posted}/{len(final)}")
        out("review_status", "success"); out("comments_posted", str(posted))

        PYEOF

branding:
  icon: 'eye'
  color: 'purple'
